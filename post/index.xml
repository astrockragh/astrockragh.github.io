<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts | Christian Kragh Jespersen</title>
    <link>https://astrockragh.github.io/post/</link>
      <atom:link href="https://astrockragh.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    <description>Posts</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>¬© Christian Kragh Jespersen 2024</copyright><lastBuildDate>Thu, 03 Oct 2024 10:00:00 +0000</lastBuildDate>
    <image>
      <url>https://astrockragh.github.io/media/logo_hu99cbd5be059c86a221a329805c1c065d_47879_300x300_fit_lanczos_3.png</url>
      <title>Posts</title>
      <link>https://astrockragh.github.io/post/</link>
    </image>
    
    <item>
      <title>Theorist or observer?</title>
      <link>https://astrockragh.github.io/post/theory_observer/</link>
      <pubDate>Thu, 03 Oct 2024 10:00:00 +0000</pubDate>
      <guid>https://astrockragh.github.io/post/theory_observer/</guid>
      <description>&lt;p&gt;A question that many astronomers often ask is whether a given person is an &lt;em&gt;observer&lt;/em&gt; or a &lt;em&gt;theorist&lt;/em&gt;. This bimodal view of our discipline is quite outdated, but nonetheless persistent. Below I give a short overview of some of the considerations people make when evaluating my position in the field, considerations that I make when answering the question, and how I see my own role.&lt;/p&gt;
&lt;h3 id=&#34;why-some-consider-me-a-theorist&#34;&gt;Why some consider me a theorist&lt;/h3&gt;
&lt;p&gt;My first series of papers in graduate school (on &lt;a href=&#34;https://astrockragh.github.io/project/mangrove&#34;&gt;galaxy formation histories&lt;/a&gt; and &lt;a href=&#34;https://astrockragh.github.io/project/gnn_environment&#34;&gt;environments&lt;/a&gt;) were all done starting from simulation data, which shaped the early talks I gave to scientific audiences, and therefore this view of me as a theorist.&lt;/p&gt;
&lt;p&gt;Furthermore, most of the people in the field of AstroxML (machine learning applied to astronomy) tend to mainly use simulated data products to tune their models, which land them in the &amp;ldquo;theory&amp;rdquo;-bin, and so do I, by association.&lt;/p&gt;
&lt;p&gt;This view is mainly wrong because, well, I really do not like using simulated data as a first approach. Philosophically, I am an &lt;strong&gt;empiricist&lt;/strong&gt;, meaning that I am only really interested in things that can be &lt;strong&gt;measured&lt;/strong&gt; in the real world, and I spend a lot of time taking, improving, and using real data from real instruments.&lt;/p&gt;
&lt;p&gt;But&amp;hellip; then, I must be an observer?&lt;/p&gt;
&lt;!-- Simulations, statistics, data analysis, machine learning --&gt;
&lt;h3 id=&#34;why-some-consider-me-an-observer&#34;&gt;Why some consider me an observer&lt;/h3&gt;
&lt;p&gt;The majority of my time at Princeton and at the University of Copenhagen has been focused on observations. My first paper was on &lt;em&gt;empirically&lt;/em&gt; &lt;a href=&#34;https://astrockragh.github.io/project/tsne_grb&#34;&gt;classifying gamma-ray bursts&lt;/a&gt;, then I worked on measuring and forecasting &lt;a href=&#34;https://astrockragh.github.io/project/high_z_jwst&#34;&gt;cosmic variance for JWST&lt;/a&gt;, writing proposals for JWST, calibrating point-spread functions for &lt;a href=&#34;https://astrockragh.github.io/project/cosmos&#34;&gt;COSMOS2020&lt;/a&gt;, then on observing &lt;a href=&#34;https://astrockragh.github.io/project/neutrino_ml&#34;&gt;neutrinos with IceCube&lt;/a&gt;. This work has continued while at Princeton, where I have been CoI on a couple of succesful JWST proposals, and thought some more about &lt;a href=&#34;https://astrockragh.github.io/project/most_massive_jwst&#34;&gt;cosmic variance&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;However, my biggest claim to being an observer has come from the times I have actually physically been observing (which I where the picture at the top of the post is from), as well as my +3 year-involvement in the engineering/commissioning teams for the Prime Focus Spectrograph (PFS) and its auxilliary telescope, the &lt;a href=&#34;https://astrockragh.github.io/project/sunss_airglow&#34;&gt;Subaru Night Sky Spectrograph (SuNSS)&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;But&amp;hellip; if I am on the engineering team, does that not mean that I do instrumentation then?&lt;/p&gt;
&lt;!-- SuNSS, PFS, observing on Hawaii, COSMOS, Beasts, Massive Quiescent galaxies with Francesco, proposals --&gt;
&lt;h3 id=&#34;why-some-consider-me-an-instrumentalist&#34;&gt;Why some consider me an instrumentalist&lt;/h3&gt;
&lt;p&gt;This is perhaps the easiest view to neglect, but it has happened that people think I only do instrumentation. This comes from the fact that I spend a good part of my time worrying about software (wavelength/flux calibration) and hardware (fiber connectors) for massively multiplexed spectrographs like PFS. However, as of now, most of what I do for these instruments is to study the &lt;a href=&#34;https://astrockragh.github.io/project/sunss_airglow&#34;&gt;airglow&lt;/a&gt;, the intrinsic emission of the night sky, and using what we find to improve the performance.
Therefore, I do not really qualify as a real instrumentalist.&lt;/p&gt;
&lt;p&gt;So if I do not fit into these bins, do I even really count as an astrophysicist?&lt;/p&gt;
&lt;!-- Software for PFS/SuNSS --&gt;
&lt;h3 id=&#34;why-some-do-not-consider-me-an-astrophysicist-at-all&#34;&gt;Why some do not consider me an astrophysicist at all&lt;/h3&gt;
&lt;p&gt;A view I have encountered from a few (mainly older) people, is that what I do has nothing to do with &amp;ldquo;real astrophysics&amp;rdquo;. This view mainly comes from people who hear that I care about statistics and machine learning, and therefore classify me as a kind of lost computer scientist.&lt;/p&gt;
&lt;p&gt;Of course, my interest in statistics and machine learning really comes from their applicability for real, physical problems, so I am definitely not just a computer scientist who got lost.&lt;/p&gt;
&lt;p&gt;But what am I then?&lt;/p&gt;
&lt;h3 id=&#34;my-profile-as-i-see-it&#34;&gt;My profile as I see it&lt;/h3&gt;
&lt;p&gt;My academic profile is a bit weird, mostly because it is very multi-faceted. This makes some people a bit uncomfortable, because they cannot quite nail me down, but I really like having an eclectic profile! The possibility for being broad is one of the main reasons I fell in love with astrophysics to begin with!&lt;/p&gt;
&lt;p&gt;I also think of astrophysics as being a fundamentally composite science, in need of broad skill-sets, and when I look at the true greats of the field, I see people who skillfully spanned everything from theory to hardware-building.&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;Of course, I do not span everything, so I have tried to summarise how I see my skill-set as of October 3rd, 2024. The results can be seen in the above radar graph.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;A radar chart of my skills&#34; srcset=&#34;
               /post/theory_observer/radar_chart_2_hu94212fd73922088eab7529ca18411157_306283_591f8d9db5bc96968b489aafcd0a73ad.webp 400w,
               /post/theory_observer/radar_chart_2_hu94212fd73922088eab7529ca18411157_306283_08e1de333d357827e40a7e06c164c415.webp 760w,
               /post/theory_observer/radar_chart_2_hu94212fd73922088eab7529ca18411157_306283_1200x1200_fit_q100_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://astrockragh.github.io/post/theory_observer/radar_chart_2_hu94212fd73922088eab7529ca18411157_306283_591f8d9db5bc96968b489aafcd0a73ad.webp&#34;
               width=&#34;760&#34;
               height=&#34;571&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;This will surely change over the years. However, I will always love measuring things. Astrophysics is only a science because we measure real things with real instruments. It is in real data that the true wonders of the universe lie.&lt;/p&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Think of people like Jim Gunn, who made fundamental contributions to everything he touched!&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
    </item>
    
    <item>
      <title>So what is your name and how do you say it?</title>
      <link>https://astrockragh.github.io/post/my_name/</link>
      <pubDate>Thu, 03 Oct 2024 00:00:00 +0000</pubDate>
      <guid>https://astrockragh.github.io/post/my_name/</guid>
      <description>&lt;h3 id=&#34;what-is-my-name&#34;&gt;What is my name?&lt;/h3&gt;
&lt;p&gt;My full name is Christian Kragh Jespersen, a very Danish üá©üá∞ name. Why is it very Danish? Well my first name is the &lt;a href=&#34;https://www.dst.dk/da/Statistik/emner/borgere/navne/hvor-mange-hedder&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;single most common name&lt;/a&gt; in Denmark (including the alternate form &amp;ldquo;Kristian&amp;rdquo;), stemming from the fact that it is one of two allowed names for male Danish monarchs. The other is Frederik, which the current Danish king, Frederik X is called. My surname is part of the patronymic naming tradition of &amp;ldquo;father&amp;rsquo;s name&amp;rdquo;+&amp;ldquo;sen&amp;rdquo; (meaning son). My last name therefore simply means &amp;ldquo;son of Jesper&amp;rdquo;. My father&amp;rsquo;s name is however &lt;strong&gt;not&lt;/strong&gt; Jesper (although one of his brothers is called Jesper), since in 1856 the state decided that it was too much trouble to keep track of changes in surnames every generation, and fixed each family&amp;rsquo;s surname to whatever it was at that time.&lt;/p&gt;
&lt;h3 id=&#34;how-should-you-write-my-name&#34;&gt;How should you write my name?&lt;/h3&gt;
&lt;p&gt;Please write it as &amp;ldquo;Jespersen, Christian Kragh&amp;rdquo;, ideally without shortening the &amp;ldquo;Kragh&amp;rdquo; to &amp;ldquo;K.&amp;rdquo;, although that is preferable to not including it. It is legally part of my first name, so that is why it should not be shortened.&lt;/p&gt;
&lt;h3 id=&#34;how-should-you-say-my-name&#34;&gt;How should you say my name?&lt;/h3&gt;
&lt;p&gt;First of all, no need to call me &amp;ldquo;Christian Kragh&amp;rdquo;, just &amp;ldquo;Christian&amp;rdquo; is fine! If you read IPA, the proper pronunciation of my name is:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Ààk ∞ Åestj√¶n Ààk ∞ Å…ëÀÄw Ààjesp…êsnÃ©&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;If not, you can find a recording of my name here: &lt;a href=&#34;https://www.name-coach.com/christiankragh-jespersen?share_trigger=true&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://www.name-coach.com/christiankragh-jespersen?share_trigger=true&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;If you can&amp;rsquo;t do the &amp;ldquo;hard r&amp;rdquo; ( Å in IPA, non-existent in English), that&amp;rsquo;s completely fine, just do whatever r fits in with what languages you already know.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Building better galaxies with Mangrove</title>
      <link>https://astrockragh.github.io/post/mangrove/</link>
      <pubDate>Mon, 19 Sep 2022 00:00:00 +0000</pubDate>
      <guid>https://astrockragh.github.io/post/mangrove/</guid>
      <description>&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Mangrove&amp;amp;rsquo;s Logo&#34; srcset=&#34;
               /post/mangrove/featured_old_hu7a91daf6b1a6feed761a05f58cec4d84_279687_0ed301d449071dd9ae425fdc4e9d0a3f.webp 400w,
               /post/mangrove/featured_old_hu7a91daf6b1a6feed761a05f58cec4d84_279687_1278bdb7b01b11e886e8712c7da4ae56.webp 760w,
               /post/mangrove/featured_old_hu7a91daf6b1a6feed761a05f58cec4d84_279687_1200x1200_fit_q100_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://astrockragh.github.io/post/mangrove/featured_old_hu7a91daf6b1a6feed761a05f58cec4d84_279687_0ed301d449071dd9ae425fdc4e9d0a3f.webp&#34;
               width=&#34;760&#34;
               height=&#34;480&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;First of all, I&amp;rsquo;ve written two versions of this post, this one is a little easier to understand (less jargon) and more fun! The other version can be found under &amp;ldquo;Research&amp;rdquo;.&lt;/p&gt;
&lt;h2 id=&#34;motivation&#34;&gt;Motivation&lt;/h2&gt;
&lt;p&gt;When scientists discover something, there are three main things that we tend to ask ourselves.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;What is the building blocks of that thing?&lt;/li&gt;
&lt;li&gt;What is keeping the building blocks together in that particular structure?&lt;/li&gt;
&lt;li&gt;How did the thing get assembled?&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;One can think of it sort of like getting a new thing from IKEA. We discover a new object, say a galaxy, and it feels like we have discovered a new item in the IKEA catalogue that is our world.&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Boxes from IKEA&#34; srcset=&#34;
               /post/mangrove/ikea_boxes_hua16e68f23b3733410713f9c2fa435ae2_928645_128d4430dd2e499ed4064fbe0abb1cb5.webp 400w,
               /post/mangrove/ikea_boxes_hua16e68f23b3733410713f9c2fa435ae2_928645_da2fa61c82a22b2929637bb1391a5e4b.webp 760w,
               /post/mangrove/ikea_boxes_hua16e68f23b3733410713f9c2fa435ae2_928645_1200x1200_fit_q100_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://astrockragh.github.io/post/mangrove/ikea_boxes_hua16e68f23b3733410713f9c2fa435ae2_928645_128d4430dd2e499ed4064fbe0abb1cb5.webp&#34;
               width=&#34;760&#34;
               height=&#34;623&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;But now we want to investigate it a bit more. We want to answer our three questions, and for that we just need to open the box and find the assembly manual, within which we find:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;What parts is included for building our galaxy, i.e. the building blocks. For galaxies this would be some stars, some dark matter, some gas and so on.&lt;/li&gt;
&lt;li&gt;What tools are included to build our galaxy. For our galaxy we mainly just need one screwdriver, gravity.&lt;/li&gt;
&lt;li&gt;The instructions for how to use our tools to put together our parts.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Question 1 is actually not as simple as it looks. When we go out and look at galaxies, we see that there seems to a building block that affects the galaxy a lot, but that we cannot see. This is what we call &lt;strong&gt;dark matter&lt;/strong&gt;. While dark matter is weird, it is also quite simple. As far as we can tell, it only interacts with other things through gravity, but it is still fundamental to how galaxies end up being. This is because it collapses under its own gravity and makes gravitational wells where galaxies can form. These collapsed clumps are called halos.&lt;/p&gt;
&lt;p&gt;Question 3 is by far the most complicated when it comes to galaxies, because it is really hard to observe. Galaxies evolve over v e r y long timescales.
Luckily, we have simulations we can investigate this with. There are a couple of key problems with the simulations though.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;They are computationally expensive.&lt;/li&gt;
&lt;li&gt;They are hard interpret/understand.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Making a model that emulates a simulation can solve problem 1 and give a lot of new insights into problem 2. So that is what we have done by building &lt;em&gt;Mangrove&lt;/em&gt;. Mangrove is a Machine Learning based emulator that takes into account all three core aspects of galaxy formations, building blocks, tools and assembly manual, to give us better galaxies faster.&lt;/p&gt;
&lt;h2 id=&#34;technical-stuff&#34;&gt;Technical stuff&lt;/h2&gt;
&lt;p&gt;First of all, we don&amp;rsquo;t completely bypass the simulation step, since we still need to run a simulation, but only one with &lt;em&gt;nothing but dark matter&lt;/em&gt;. Because dark matter is so simple, this can be done pretty quickly. Then, once we have that simulation, we can try to &amp;ldquo;paint&amp;rdquo; galaxies on top of the dark matter. This is by no means the first time this has been attempted, but earlier papers have only included features from the final time step of the simulation as their input to their model. This essentially means that these methods can learn answers to questions 1 and 2 (current building blocks/tools), but are agnostic about the assembly of the galaxies. Mangrove improves on this by using not just the final time step, but an encoding of the temporal evolution of the dark matter known as a &lt;strong&gt;merger tree&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;The merger tree is made by simply stopping the simulation at different time steps and identifying the halos where we know that galaxies live. We then see which halos merge with other halos from timestep to timestep, and build a tree-like structure encoding this evolution (see Fig. 1).&lt;/p&gt;
&lt;!-- ![]() --&gt;
&lt;figure&gt;
&lt;img src=&#34;graphic1.png&#34; alt=&#34;First graphic&#34; style=&#34;width:100%&#34;&gt;
&lt;figcaption align = &#34;center&#34;&gt;&lt;b&gt;Fig.1 - Running a simulation and identifying halos at different time steps allows us to build the merger tree, which can then easily be encoded as a graph. &lt;/b&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;We can then encode the merger tree as a mathematical &lt;strong&gt;graph&lt;/strong&gt;, which in this context simply means a collection of nodes and edges, where each node represents a halo, and the edges determine how they have interacted with each other over time. When we have the graphs we can use a &lt;a href=&#34;https://en.wikipedia.org/wiki/Graph_neural_network&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Graph Neural Network (GNN)&lt;/a&gt;, to learn how the galaxies pertaining to those merger trees should be.&lt;/p&gt;
&lt;p&gt;In order to build an emulator, we also have to find something to emulate. In this post I discuss results from emulating the outputs from a Semi-Analytic Model&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt; but it works just as well for other kinds of simulations, like magneto-hydrodynamical simulations like &lt;a href=&#34;https://www.tng-project.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;IllustrisTNG&lt;/a&gt;!&lt;/p&gt;
&lt;p&gt;Mangrove is a Graph Neural Network (GNN). GNNs work by acting on both nodes, and the &lt;strong&gt;neighbourhood&lt;/strong&gt; of that node, meaning all the nodes that is connected to it by an edge.
The way we learn from both nodes and neighbourhoods is through &lt;em&gt;Message Passing&lt;/em&gt;. Message passing means that each node sends information about its current state along the edges of the graph, and is then updated by a learnable&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt; function &lt;em&gt;f&lt;/em&gt;. This information passed along the edges is then used to update the state of the node through another learnable&lt;sup id=&#34;fnref:2&#34;&gt;&lt;a href=&#34;#fn:2&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;2&lt;/a&gt;&lt;/sup&gt; function &lt;em&gt;g&lt;/em&gt;.&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&#34;graphic2.png&#34; alt=&#34;Second graphic&#34; style=&#34;width:100%&#34;&gt;
&lt;/figure&gt;
&lt;figure&gt;
&lt;img src=&#34;graphic3.png&#34; alt=&#34;Second graphic&#34; style=&#34;width:100%&#34;&gt;
&lt;figcaption align = &#34;center&#34;&gt;&lt;b&gt;Fig.2 - Messages are passed along edges, and the nodes are updated. The updated nodes are then summed over and decoded to give us the properties of the galaxy that resulted from that merger tree. &lt;/b&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;After doing a couple of these message passing steps, we then sum over all halos in the merger tree and use &lt;strong&gt;yet another learnable function&lt;/strong&gt; &lt;em&gt;h&lt;/em&gt;, that decodes this sum and predicts the aspects of galaxies that we are interested in, such as the total mass of the stars in the galaxy, the mass of the black hole at the center and the amount of cold gas, as well as the uncertainties on these quantities.&lt;/p&gt;
&lt;p&gt;We like having uncertainties on our predictions, since we recognize that there might be a little area around the true value that would also be reasonable to predict. Furthermore, it gives the model the possiblity of simply letting us know if it doesn&amp;rsquo;t know what&amp;rsquo;s going on, instead of making a foolhardy guess.&lt;/p&gt;
&lt;h2 id=&#34;results&#34;&gt;Results&lt;/h2&gt;
&lt;p&gt;How much better does Mangrove do compared to methods you ask?&lt;/p&gt;
&lt;p&gt;Well, let&amp;rsquo;s compare how well assign stellar masses to halos work with different methods!&lt;/p&gt;
&lt;p&gt;The first comparison is with the traditional method for assigning galaxy properties based on their dark matter halos, Abundance Matching. Abundance Matching is quite simple, assuming only that there exists a monotonic relationship between halo and galaxy properties. That means that if we were to assign stellar masses to the halos, the most massive halo would get the highest stellar mass, the least massive the least stellar mass and so on. If we compare the abundance matched relationship to the one we predict, we see a dramatic difference.&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&#34;precision_abundance_match.png&#34; alt=&#34;precision graphic one&#34; style=&#34;width:100%&#34;&gt;
&lt;figcaption align = &#34;center&#34;&gt;&lt;b&gt;Fig.3 - We show the relationship between what we are supposed to be getting on the x-axis and what we actually predict using either method on the y-axis. A perfect prediction would mean that all point were on the diagonal, therefore the goal is to cluster as tightly around the diagonal as possible. The difference is quite apparent. &lt;/b&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;But, that is perhaps an unfair comparison. We use machine learning after all, and abundance matching uses nothing but a single number per halo.&lt;/p&gt;
&lt;p&gt;We should then maybe compare to other machine learning methods that use a lot of information &lt;em&gt;but&lt;/em&gt; only from the final halo. That seems more fair.&lt;/p&gt;
&lt;p&gt;But as is apparent, Mangrove still outperforms this by about a factor of 2 when measured by how much the two methods deviate from perfect predictions.&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&#34;precision_halo.png&#34; alt=&#34;precision graphic two&#34; style=&#34;width:100%&#34;&gt;
&lt;figcaption align = &#34;center&#34;&gt;&lt;b&gt;Fig.4 - Same as Fig. 3, but comparing to the state of the art machine learning techniques. The difference is still striking. &lt;/b&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;Mangrove can also predict a lot of other things, like the amount of cold gas in a galaxy (M&lt;sub&gt;cold&lt;/sub&gt;), how fast it is making stars right now (Star Formation Rate/SFR), how much metal there is in the gas (Z&lt;sub&gt;gas&lt;/sub&gt;) and the mass of the black hole at its center (M&lt;sub&gt;BH&lt;/sub&gt;).&lt;/p&gt;
&lt;p&gt;Mangrove does better than all of the above mentioned methods across the board.&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&#34;precision_others.png&#34; alt=&#34;precision graphic three&#34; style=&#34;width:100%&#34;&gt;
&lt;figcaption align = &#34;center&#34;&gt;&lt;b&gt;Fig.5 - Same as Fig. 4/5, but here we show how other galaxy properties, all improvements over the current state of the art. &lt;/b&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;h3 id=&#34;other-fun-things&#34;&gt;Other fun things&lt;/h3&gt;
&lt;p&gt;Now that we have a well-working model, we can then try to figure out where the improvement comes from. Is it in the first few timesteps, the initial conditions? Can we make galaxies at different spots in time?&lt;/p&gt;
&lt;p&gt;The answer to the last question turns out to be yes. If we take a single Mangrove model and train it at several different times (we encode this as a &lt;a href=&#34;https://en.wikipedia.org/wiki/Redshift&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;redshift&lt;/a&gt;, usually written as a &lt;strong&gt;z&lt;/strong&gt;), we see that it both does well at the new times, but also in between!&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&#34;interpolation.png&#34; alt=&#34;interpolation&#34; style=&#34;width:100%&#34;&gt;
&lt;figcaption align = &#34;center&#34;&gt;&lt;b&gt;Fig.6 - Mangrove can do galaxies across time, and interpolate to timesteps it has never seen before! &lt;/b&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;In terms of removing things from the model, we tried to simply cut down the merger tree from above, leaving out the very earliest halos. We found that the closer you get to the present day, the more each halo matters. The effect is so strong that removing the first half of the merger tree doesn&amp;rsquo;t matter much, but removing the final 1% is measurable!&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&#34;trimming.png&#34; alt=&#34;interpolation&#34; style=&#34;width:100%&#34;&gt;
&lt;figcaption align = &#34;center&#34;&gt;&lt;b&gt;Fig.7 - By removing parts of the merger tree, we see that most of the information comes from times closer to the present day. &lt;/b&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;h1 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;If there is one thing that one should remember from this paper, it is that the long-standing &amp;rsquo;nature versus nurture&amp;rsquo; debate is not just for humans. It also matters for galaxies, and with our code, Mangrove, we can take both aspects into account, and make big improvements!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;It matters &lt;em&gt;how&lt;/em&gt; we build our galaxies!&lt;/strong&gt;&lt;/p&gt;
&lt;h2 id=&#34;code&#34;&gt;Code&lt;/h2&gt;
&lt;p&gt;Anyone who wishes to do anything similar to this project is encouraged &lt;a href=&#34;https://ui.adsabs.harvard.edu/search/p_=0&amp;amp;q=author%3A%22Jespersen%2C%20Christian%20K.%22&amp;amp;sort=date%20desc%2C%20bibcode%20desc&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;read the paper&lt;/a&gt; and check out the &lt;a href=&#34;https://github.com/astrockragh/Mangrove&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Github&lt;/a&gt;. All the code used for the projects is free to use, although I do not guarantee that it will be easy to find your way around in it!&lt;/p&gt;
&lt;section class=&#34;footnotes&#34; role=&#34;doc-endnotes&#34;&gt;
&lt;hr&gt;
&lt;ol&gt;
&lt;li id=&#34;fn:1&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Semi Analytic Models are a kind of simulation that is run after running a simulation of only the dark matter in the universe. A good early reference is &lt;a href=&#34;https://arxiv.org/pdf/astro-ph/9802268.pdf&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://arxiv.org/pdf/astro-ph/9802268.pdf&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:1&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id=&#34;fn:2&#34; role=&#34;doc-endnote&#34;&gt;
&lt;p&gt;Any time I mention a &amp;ldquo;learnable function&amp;rdquo;, think about it as a very basic neural network, what we call a Multi-Layer Perceptron (MLP). An illustration of an MLP can be found at &lt;a href=&#34;https://en.wikipedia.org/wiki/Neural_network#/media/File:Neural_network_example.svg&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://en.wikipedia.org/wiki/Neural_network#/media/File:Neural_network_example.svg&lt;/a&gt;&amp;#160;&lt;a href=&#34;#fnref:2&#34; class=&#34;footnote-backref&#34; role=&#34;doc-backlink&#34;&gt;&amp;#x21a9;&amp;#xfe0e;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</description>
    </item>
    
  </channel>
</rss>
